{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14adc91a",
   "metadata": {},
   "source": [
    "# K-Clustering Tool for Edge Devices\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### 1. Feature Definition and Data Collection\n",
    "- Select measurable features suitable for edge devices (size, color, brightness, sensor data).\n",
    "- Collect data from devices or public datasets.\n",
    "- Normalize and store data efficiently for limited hardware.\n",
    "\n",
    "### 2. K-Means Classification on Edge Devices\n",
    "- Implement a lightweight K-Means algorithm optimized for CPU/GPU constraints.\n",
    "- Use reduced memory operations and optional medoid-style center updates.\n",
    "- Compare center initialization methods:\n",
    "  - Random\n",
    "  - PCA-based\n",
    "  - Nearest raw point (K-Medoids approach)\n",
    "- Final script executes the full pipeline and shows result variation based on initial centers.\n",
    "\n",
    "### 3. Integration with Split Inference\n",
    "- Extract features on the edge device to minimize bandwidth.\n",
    "- Perform clustering locally for real-time classification.\n",
    "- Offload model retraining to the cloud.\n",
    "- Synchronize updated cluster centers back to devices with minimal data transfer.\n",
    "### 4. Resource \n",
    "- [StackOverflow](https://stackoverflow.com/questions/35952124/how-to-choose-initial-centroids-for-k-means-clustering)\n",
    "- [Init centroids smarter](https://medium.com/@atharv4study/k-means-smarter-initialization-for-better-clustering-6914a473e1c7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be870e",
   "metadata": {},
   "source": [
    "### 1. Define feature and collect data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5cff26",
   "metadata": {},
   "source": [
    "### 2. Build algorithm "
   ]
  },
  {
   "cell_type": "code",
   "id": "333012d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.433084Z",
     "start_time": "2025-12-05T16:25:27.429716Z"
    }
   },
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "e8387cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.443422Z",
     "start_time": "2025-12-05T16:25:27.440096Z"
    }
   },
   "source": [
    "# config \n",
    "NUM_CLUSTERS = 2\n",
    "MAX_ITERATIONS = 500 "
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "2bfc881f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.495342Z",
     "start_time": "2025-12-05T16:25:27.449296Z"
    }
   },
   "source": [
    "data = pd.read_csv(\"data_device.csv\")\n",
    "raw_points = list(data.values)\n",
    "raw_points = np.delete(raw_points, 0 , axis=1)\n",
    "\n",
    "# Manual normalization\n",
    "points, min_vals, max_vals = min_max_normalize(raw_points)\n",
    "\n",
    "# CPU & Core slightly emphasized after scaling\n",
    "FEATURE_INDEX = {\n",
    "\"Total Ram\": 0,\n",
    "\"Storage\": 1,\n",
    "\"Internet\": 2,\n",
    "\"Core\": 3\n",
    "}\n",
    "\n",
    "WEIGHTS = {\n",
    "    \"Core\": 1.4,\n",
    "    \"Total Ram\": 1.2,\n",
    "    \"Internet\": 1.1,\n",
    "    \"Storage\": 0.65\n",
    "}\n",
    "\n",
    "points = np.array(points)\n",
    "\n",
    "for feat, w in WEIGHTS.items():\n",
    "    points[:, FEATURE_INDEX[feat]] *= w\n",
    "\n",
    "points = points.tolist()\n",
    "\n",
    "# Run K-means on full-dimensional data\n",
    "final_centers, clusters, init_centers = kmeans(\n",
    "    points=points,\n",
    "    num_clusters=NUM_CLUSTERS,\n",
    "    max_iterations=MAX_ITERATIONS\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "0ba91c09",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae27ecfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.504575Z",
     "start_time": "2025-12-05T16:25:27.500689Z"
    }
   },
   "source": [
    "def min_max_normalize(data):\n",
    "    \"\"\"\n",
    "    Perform Min-Max normalization on a dataset without using any external library.\n",
    "\n",
    "    Args:\n",
    "        data : list of samples\n",
    "               shape = (N, D)\n",
    "\n",
    "    Returns:\n",
    "        normalized_data : same shape as input, values scaled into [0, 1]\n",
    "        min_vals        : list[D]\n",
    "        max_vals        : list[D]\n",
    "    \"\"\"\n",
    "    \n",
    "    num_features = len(data[0])\n",
    "\n",
    "    # ---- find min & max for each feature ----\n",
    "    min_vals = [float(\"inf\")] * num_features\n",
    "    max_vals = [float(\"-inf\")] * num_features\n",
    "\n",
    "    for row in data:\n",
    "        for i, val in enumerate(row):\n",
    "            if val < min_vals[i]:\n",
    "                min_vals[i] = val\n",
    "            if val > max_vals[i]:\n",
    "                max_vals[i] = val\n",
    "\n",
    "    # ---- normalize ----\n",
    "    normalized_data = []\n",
    "    \n",
    "    for row in data:\n",
    "        norm_row = []\n",
    "        for i, val in enumerate(row):\n",
    "\n",
    "            # Avoid divide-by-zero if data column is constant\n",
    "            if max_vals[i] == min_vals[i]:\n",
    "                scaled = 0.0\n",
    "            else:\n",
    "                scaled = (val - min_vals[i]) / (max_vals[i] - min_vals[i])\n",
    "            \n",
    "            norm_row.append(scaled)\n",
    "\n",
    "        normalized_data.append(norm_row)\n",
    "\n",
    "    return normalized_data, min_vals, max_vals"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "556c89fe",
   "metadata": {},
   "source": [
    "#### Basic distance"
   ]
  },
  {
   "cell_type": "code",
   "id": "93ee6e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.513025Z",
     "start_time": "2025-12-05T16:25:27.509007Z"
    }
   },
   "source": [
    "def euclidean_distance(point1: List[float], point2: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance between two N-D points.\n",
    "\n",
    "    This implementation avoids numpy heavy operations to reduce RAM usage,\n",
    "    making it suitable for edge devices.\n",
    "    \"\"\"\n",
    "    s = 0.0\n",
    "    for x, y in zip(point1, point2):\n",
    "        s += (x - y) ** 2\n",
    "    return math.sqrt(s)\n",
    "\n",
    "\n",
    "def min_distance_to_centroids(point: List[float], centroids: List[List[float]]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the minimum distance from 'point' to all existing centroids.\n",
    "    Used by the farthest-point initialization heuristic.\n",
    "    \"\"\"\n",
    "    return min(euclidean_distance(point, c) for c in centroids)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "3a64eda7",
   "metadata": {},
   "source": [
    "#### Farthetst-point centroid initialization "
   ]
  },
  {
   "cell_type": "code",
   "id": "c0d2323d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.522061Z",
     "start_time": "2025-12-05T16:25:27.518017Z"
    }
   },
   "source": [
    "def select_next_centroid(centroids: List[List[float]],\n",
    "                          points: List[List[float]]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Select the next centroid using the farthest-point heuristic.\n",
    "\n",
    "    The next centroid is chosen as the point which has the greatest\n",
    "    minimum distance to the existing centroid set.\n",
    "\n",
    "    This technique improves initialization stability over random sampling.\n",
    "    \"\"\"\n",
    "    best_candidate = None\n",
    "    max_dist = -1\n",
    "\n",
    "    for p in points:\n",
    "        dist = min_distance_to_centroids(p, centroids)\n",
    "\n",
    "        # Avoid duplicate centroid selection\n",
    "        already_selected = any(np.allclose(p, c) for c in centroids)\n",
    "\n",
    "        if dist > max_dist and not already_selected:\n",
    "            max_dist = dist\n",
    "            best_candidate = p\n",
    "\n",
    "    return best_candidate"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "1a3d9bb1",
   "metadata": {},
   "source": [
    "#### Nearest raw data point mapping "
   ]
  },
  {
   "cell_type": "code",
   "id": "3db80ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.530860Z",
     "start_time": "2025-12-05T16:25:27.527776Z"
    }
   },
   "source": [
    "def nearest_point(raw_points: List[Tuple[float, float]],\n",
    "                  target: Tuple[float, float]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Find the real data point closest to a centroid.\n",
    "\n",
    "    This is important for edge-device deployment where cluster\n",
    "    representatives must be real measurable samples.\n",
    "    \"\"\"\n",
    "    best = None\n",
    "    best_dist = float(\"inf\")\n",
    "\n",
    "    for p in raw_points:\n",
    "        d = euclidean_distance(p, target)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best = p\n",
    "\n",
    "    return best\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "3dd01531",
   "metadata": {},
   "source": [
    "#### K clustering "
   ]
  },
  {
   "cell_type": "code",
   "id": "c94d0f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.541240Z",
     "start_time": "2025-12-05T16:25:27.535778Z"
    }
   },
   "source": [
    "def kmeans(points: List[List[float]],\n",
    "           num_clusters: int,\n",
    "           max_iterations: int):\n",
    "    \"\"\"\n",
    "    Perform manual K-Means clustering.\n",
    "\n",
    "    Steps:\n",
    "    1. Initialize centroids using random + farthest-point heuristics.\n",
    "    2. Iteratively assign points to closest centroid.\n",
    "    3. Update centroids as cluster means.\n",
    "    4. Stop when centroids converge or iteration limit is reached.\n",
    "    5. Map centroids to nearest real data points.\n",
    "\n",
    "    Returns:\n",
    "        final_centers   : Closest raw points to converged centroids\n",
    "        clusters        : List of k clusters\n",
    "        initial_centers : Snapshot of centroid initialization\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- STEP 1: Initialization ----\n",
    "\n",
    "    # Pick 1 random starting centroid\n",
    "    centroids = random.sample(points, 1)\n",
    "\n",
    "    # Use farthest-point heuristic to select remaining centroids\n",
    "    while len(centroids) < num_clusters:\n",
    "        new_centroid = select_next_centroid(centroids, points)\n",
    "        centroids.append(new_centroid)\n",
    "\n",
    "    initial_centers = centroids.copy()  # For visualization or debugging\n",
    "\n",
    "    # ---- STEP 2: ITERATIVE REFINEMENT ----\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "\n",
    "        clusters = [[] for _ in range(num_clusters)]\n",
    "\n",
    "        # ------ Assignment step -------\n",
    "        for p in points:\n",
    "            distances = [euclidean_distance(p, c) for c in centroids]\n",
    "            cluster_id = distances.index(min(distances))\n",
    "            clusters[cluster_id].append(p)\n",
    "\n",
    "        # ------ Update step -------\n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "\n",
    "            if not cluster:\n",
    "                new_centroids.append(random.choice(points))\n",
    "                continue\n",
    "\n",
    "            centroid = np.mean(cluster, axis=0).tolist()\n",
    "            new_centroids.append(centroid)\n",
    "\n",
    "        # ------ Convergence check -------\n",
    "        if np.allclose(np.array(new_centroids), np.array(centroids), atol=1e-6):\n",
    "            print(f\"K-Means converged at iteration {iteration}.\")\n",
    "            break\n",
    "\n",
    "    # ---- STEP 3: Map centroids to nearest real data points ----\n",
    "\n",
    "    final_centers = [\n",
    "        nearest_point(points, centroid)\n",
    "        for centroid in centroids\n",
    "    ]\n",
    "\n",
    "    return final_centers, clusters, initial_centers"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "a777069c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T16:25:27.547858Z",
     "start_time": "2025-12-05T16:25:27.545793Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
